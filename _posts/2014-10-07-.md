---
layout: post
categories:
  - thesis
---

Big differences in Kalibr calibration output after running on different (but similar) datasets.

Toby suggested to see if similar calibration results are produced when calibrating on similar datasets.  They do not.

Output of run 1 (clipped for convenience):

```
Calibration results
===================
Reprojection error squarred (cam0):  mean 158.11442896, median 61.7137172413, std: 295.253309102
Gyro error squarred (imu0):          mean 155.557683634, median 35.1275061508, std: 334.534396877
Accelerometer error squarred (imu0): mean 192.101807079, median 82.5503712238, std: 323.296002138

Transformation (cam0):
-----------------------
T_ci:  (imu to cam0): [m]
[[ 0.91478631 -0.20700352 -0.34686531 -0.07009326]
 [-0.32315093 -0.89026033 -0.32095174  0.02824299]
 [-0.24236228  0.40569211 -0.88129135 -0.06450264]
 [ 0.          0.          0.          1.        ]]

T_ic:  (cam0 to imu): [m]
[[ 0.91478631 -0.32315093 -0.24236228  0.05761409]
 [-0.20700352 -0.89026033  0.40569211  0.03680227]
 [-0.34686531 -0.32095174 -0.88129135 -0.0720939 ]
 [ 0.          0.          0.          1.        ]]

timeshift cam0 to imu0: [s] (t_imu = t_cam + shift)
-0.0091828305936


Gravity vector in target coords: : [m/s^2]
[ 3.98739679 -8.95312365  0.42230769]
```

And output for run 2:

```
Calibration results
===================
Reprojection error squarred (cam0):  mean 148.637347345, median 72.805393783, std: 226.471479229
Gyro error squarred (imu0):          mean 34.4248620544, median 3.23377268184, std: 168.492839464
Accelerometer error squarred (imu0): mean 55.7155925663, median 4.47706594705, std: 162.437054178

Transformation (cam0):
-----------------------
T_ci:  (imu to cam0): [m]
[[ 0.93218117 -0.16942296 -0.31989707 -0.10233415]
 [-0.18716123 -0.98200328 -0.02530275  0.01110253]
 [-0.3098531   0.08345908 -0.94711437 -0.1089552 ]
 [ 0.          0.          0.          1.        ]]

T_ic:  (cam0 to imu): [m]
[[ 0.93218117 -0.18716123 -0.3098531   0.06371183]
 [-0.16942296 -0.98200328  0.08345908  0.00265827]
 [-0.31989707 -0.02530275 -0.94711437 -0.13564851]
 [ 0.          0.          0.          1.        ]]

timeshift cam0 to imu0: [s] (t_imu = t_cam + shift)
-0.00678132079955


Gravity vector in target coords: : [m/s^2]
[ 2.03584646, -9.35434891, -2.14186499]))
```

Important differences (and factor `result_1 / result_2`):

- Mean gyro and accelerometer error squared (4.52, 3.45)
- Translational component of `T_ci` norm (0.663 cm)
- **should inspect difference in rotation?**

Rereading the [article on Kalibr](#furgale2013unified):

> We routed all sensor data streams through an FPGA, recording the timestamps at the moment the image sensors were triggered and an IMU data request was initialized.  Note that while using an FPGA for data acquisition helps with avoiding stochastic delays introduced by rescheduling tasks on a processor, it does not tackle the issue of logic and filter delays inside the sensors, and in our setup does not account for communication delays introduced when polling measurements.

They also use a camera with a global shutter.  However, my C920 and the cameras (uEye model UI1008XS-C) on the Marty AR helmet all have electronic rolling shutters (source [1](http://www.m-service.de/seiten/gb/downloads_gb_only/gb_CV-UI-1008-XS-C.pdf), [2](http://eshop.abbas.cz/Files/machine%20vision/datasheety/usb%20ui-1008xs.pdf)).

I want to be able to use the global shutter camera from the Delft lab.  It is a uEye UI324xLE-M.  I installed the software from IDS's website for USB 2.0 cameras (laptop does not support USB 3.0) and installed Ubuntu package `ros-indigo-ueye`.  I activated the camera with:

```
$ roslaunch ueye nodelets.launch auto_exposure:=true
```
With ROS's `cameracalibration` package, I obtained the calibration parameters:

```
$ rosrun camera_calibration cameracabrator.py -s 9x6 -p chessboard -q 0.0255 image:=/image_raw camera:=/

<<<<< CLIP >>>>>

('D = ', [-0.2783043764360902, 0.06367231767389497, -0.0013378551011069518, 0.0010701755096373653, 0.0])
('K = ', [607.3311891949054, 0.0, 651.1699288541727, 0.0, 606.1492848834474, 523.2608014927322, 0.0, 0.0, 1.0])
('R = ', [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0])
('P = ', [441.1659240722656, 0.0, 652.3111544961466, 0.0, 0.0, 454.8569641113281, 525.1424540474618, 0.0, 0.0, 0.0, 1.0, 0.0])
None
# oST version 5.0 parameters


[image]

width
1280

height
1024

[narrow_stereo]

camera matrix
607.331189 0.000000 651.169929
0.000000 606.149285 523.260801
0.000000 0.000000 1.000000

distortion
-0.278304 0.063672 -0.001338 0.001070 0.000000

rectification
1.000000 0.000000 0.000000
0.000000 1.000000 0.000000
0.000000 0.000000 1.000000

projection
441.165924 0.000000 652.311154 0.000000
0.000000 454.856964 525.142454 0.000000
0.000000 0.000000 1.000000 0.000000
```

Later, I tried to start the camera, but now with the configuration file:

```
$ roslaunch ueye nodelets.launch auto_exposure:=true frame_rate:=20 config_path:=/home/pkok/.ros/camera_info/ueye.yaml __ns:=camera

<<<<< CLIP >>>>>

[ WARN] [1412698319.646430475]: Failed to load intrinsics for camera from file
```

Setting the parameters over the service with the command line:

```
cat /home/pkok/.ros/camera_info/test.yaml | rosservice -- call /camera/set_camera_info
```
But I got no values returned/printed.  Doing the same through RQT's Service Caller raised some errors (there was a fire drill in the building, I shut down my laptop before storing error, and left the sensor behind) about string length (received length 7 (or 4) and expected length 4 (or 7)).

{% include bibliography.html keys="furgale2013unified" %}
