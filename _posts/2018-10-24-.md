---
layout: post
categories:
  - thesis
---

Improved the motion blur module by implementing a modified version of [Zheng et al.](#zheng2006enhanced)'s method.

I found this by going through [Navarro et al.](#navarro2011motionblur)'s review paper of all kinds of motion blur.  Navarro et al. tell us that there are several categories for motion blurring processes.  Methodologies that are of interest for us are those that can be added in a post-processing step, as opposed to, for example, those that act during the rendering process.  Methods of interest include [Potmesil and Chakravarty](#potmesil1983modeling) who apply a series of image degrading transforms represented by point-spread functions; [Brostow and Essa](#brostow2001image) who have developed a method for stop-motion films that segmentates foreground from background with hierarchical optical flow and uses no scene information at all; and [Zheng et al.](#zheng2006enhanced) who combine motion information from the ray tracer and optical flow.  Appealing from Zheng et al. is that their method degrades gracefully when no ray tracer information is available at all, and then follows a simple model.

The modified Zheng model can be described as follows.

1. Name the set $$C$$ of all image coordinates $$(x,y)$$ of source image $$I$$.
2. Make the new blurred image $$B$$ a copy of $$I$$
3. Compute the motion vectors $$F(x,y) = (u_{xy}, v_{xy})$$ for each pixel $$I(x,y)$$ in the source image.  For this, I have used [Farneb√§ck](#farneback2003twoframe)'s method as implemented in OpenCV 3.3.1.
4. Let $$C'$$ be those image coordinates $$(x,y)$$ where the amount of motion $$\|F(x,y)\|$$ is less than some threshold $$\theta$$: $$C' = \{(x,y) : \|F(x,y)\| < \theta, (x,y) \in C\}$$.  In my current setup, I have set $$\theta$$ to $$3$$.  This reduces computation time (because fewer pixels will be blurred), but reduces the faithfulness (?) of the motion blur simulation.  This loss in faithfulness can be forgiven as we are talking about the slightest amount of motion which wouldn't be a challenge for the used feature detector most probably.
5. Find the maximum distance of blurring $$D = \max_{x,y} \|F(x,y)\|$$.  This will be the number of samples we will take over each motion vector.
6. We create a new blurred image $$I_B$$: for each coordinate $$(x,y) \in C$$:
    1. If $$(x,y) \in C'$$: $$I_B(x,y) = I(x,y)$$
    2. Else: $$I_B(x,y) = \mbox{avg}_D(I(x,y), I(x+u_{xy}, y+v_{xy}))$$.  The new blurred pixel $$I_B(x,y)$$ is the average of $$D$$ sampled values over the line from $$I(x,y)$$ to $$I(x+u_{xy}, y+v_{xy})$$.
7. Return $$I_B$$.

{% include bibliography.html keys="zheng2006enhanced,navarro2011motionblur,potmesil1983modeling,brostow2001image,farneback2003twoframe" %}
