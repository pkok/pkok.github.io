---
layout: post
categories:
  - thesis
---

New mission: replace the camera's orientation with information of the IMU.  More detailed problem description:


## Problem description ##
Given is a vision-inertial tracking system with the following four frames of reference:

- IMU: *i*
- Camera: *c*
- Marker: *m*
- World: *w*

Each frame *f* has a pose (rotation/orientation and translation/position) *T(g, f) = R(g, f) ∘ t(g, f)* with respect to the other frames *g*.  *T(f) = R(f) ∘ t(f)* denote the frame's absolute pose (or, shorthand for *T(w, f) = R(w,f) ∘ t(w,f)*).

*T()*, *R()* and *t()* can be represented as 4×4 matrices, but I will try to keep the discussion representation independent.

See below image for their relationships:

```
 R(i)
+-----+ T(c,i) +--------+
| IMU |<-------| camera |
+-----+        +--------+
                   |
                   | T(c,m)
                   |
                   v
               +--------+                 +-------+
               | marker |                 | world |
               +--------+                 +-------+
```

*T(c,i)* is fixed, because frames *c* and *i* are attached to the same rigid body.

*R(i)* is observed by the IMU.

*T(c, m)* is observed by the camera.

Assume that the perception of *T(c, m)* is noisy, especially *R(c, m)*.  This implies that *R(c)* is noisy as well.

Find a method to update *R(c)* from the IMU's data *R(i)*.  Try to keep *t(c)* constant.
