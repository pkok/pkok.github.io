---
layout: post
title: The start
categories:
- thesis
---

Today I had a talk with Toby.  I got some (seemingly) simple instructions for now:

1. **Read out an IMU with a programming language or to file**
   I got a [MinIMU-9 v2 (L3GD20 and LSM303DLHC carrier) of Pololu](http://www.pololu.com/product/1268), which you can hook up with an Arduino. 
2. **Track a camera's distance with respect to a marker**
   Toby suggested to use [ArUco](http://www.uco.es/investiga/grupos/ava/node/26), which should be easy.  I can use my laptop's webcam, or a [Logitech C920](http://www.logitech.com/en-us/product/hd-pro-webcam-c920).
3. **Perform a simple kind of fusion between the tracked position and the IMU data**
   Show that the IMU can improve the pose estimate of the tracker, for instance, by either pre- or postprocessing ArUco's output.

There is also some theoretical stuff to do:

4. **Read in on Kalman filters**
   The online lectures of [Cyrill Stachniss](http://ais.informatik.uni-freiburg.de/teaching/ws12/mapping/) were recommended.  I should also do the homework.
5. **In [Caarls](#caarls2009pose)' PhD thesis, read up on specific Kalman filters and "continuous time processes"**
   Because the IMU generates more often new data than the cameras, integrating this needs investigation.  
6. **Collect papers on IMU -- (stereo)camera fusion**
   If finished with all, search for papers on SLAM/PTAM methods that introduce some method of fusing these two sensors.

I started with the first practical step.  I installed the `arduino` package for Ubuntu, and did what the [related Pololu software](https://github.com/pololu/minimu-9-ahrs-arduino) told me to do.  To see if the provided drift correction works properly, I taped it down the table and let it run for some time.  Results will follow with and without drift correction.

{% include bibliography.html keys="caarls2009pose" %}
